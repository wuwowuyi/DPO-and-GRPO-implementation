model_for: sft
model: gpt2-xl
dtype: bfloat16


temperature: 0.7
batch_size: 32
lr: 0.000025
min_lr: 0.0000025
epoch: 1

activation_checkpointing: True

checkpoint_type: FULL_STATE_DICT # SHARDED_STATE_DICT, or FULL_STATE_DICT
checkpoint_folder: checkpoint
model_save_name: sft_gpt2-xl
dist_checkpoint_root_folder: checkpoint
dist_checkpoint_folder: shard
save_using_num_threads: 8
